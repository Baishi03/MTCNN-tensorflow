{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_P12_classify_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tool import IoU\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "begin=time.time()\n",
    "\n",
    "WIDER_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\WIDER_train\\\\images\"\n",
    "WIDER_spilt_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\wider_face_split\\\\wider_face_train_bbx_gt.txt\"\n",
    "negative_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\12\\\\negative\"\n",
    "positive_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\12\\\\positive\"\n",
    "par_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\12\\\\part\"\n",
    "save_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\12\"\n",
    "\n",
    "if not os.path.exists(positive_dir):\n",
    "    os.makedirs(positive_dir)\n",
    "if not os.path.exists(par_dir):\n",
    "    os.makedirs(par_dir)\n",
    "if not os.path.exists(negative_dir):\n",
    "    os.makedirs(negative_dir)\n",
    "\n",
    "f1 = open(os.path.join(save_dir, 'pos_12.txt'), 'w')\n",
    "f2 = open(os.path.join(save_dir, 'neg_12.txt'), 'w')\n",
    "f3 = open(os.path.join(save_dir, 'par_12.txt'), 'w')    \n",
    "\n",
    "with open(WIDER_spilt_dir) as filenames:\n",
    "    p=0\n",
    "    neg_idx=0\n",
    "    pos_idx=0\n",
    "    par_idx=0\n",
    "    for line in filenames.readlines():\n",
    "        line=line.strip().split(' ')\n",
    "        if(p==0):\n",
    "            pic_dir=line[0]\n",
    "            p=1\n",
    "            boxes=[]\n",
    "        elif(p==1):\n",
    "            k=int(line[0])\n",
    "            p=2\n",
    "        elif(p==2):\n",
    "            b=[]            \n",
    "            k=k-1\n",
    "            if(k==0):\n",
    "                p=0                \n",
    "            for i in range(4):\n",
    "                b.append(int(line[i]))\n",
    "            boxes.append(b)\n",
    "            # format of boxes is [x,y,w,h]\n",
    "            if(p==0):\n",
    "                img=cv2.imread(os.path.join(WIDER_dir,pic_dir).replace('/','\\\\'))\n",
    "                h,w,c=img.shape\n",
    "                \n",
    "                #save num negative pics whose IoU less than 0.3\n",
    "                num=50\n",
    "                while(num):\n",
    "                    size=randint(12,min(w,h)/2)\n",
    "                    x=randint(0,w-size)\n",
    "                    y=randint(0,h-size)\n",
    "                    if(np.max(IoU(np.array([x,y,x+size,y+size]),np.array(boxes)))<0.3):\n",
    "                        resized_img = cv2.resize(img[y:y+size,x:x+size,:], (12, 12))\n",
    "                        cv2.imwrite(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)),resized_img)\n",
    "                        f2.write(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)) + ' 0\\n')\n",
    "                        neg_idx=neg_idx+1\n",
    "                        num=num-1       \n",
    "#                 num=40\n",
    "                for box in boxes:\n",
    "                    if((box[0]<0)|(box[1]<0)|(max(box[2],box[3])<20)|(min(box[2],box[3])<=5)): \n",
    "                        continue  \n",
    "                    x1, y1, w1, h1 = box\n",
    "                    \n",
    "                    # crop another 5 images near the bounding box if IoU less than 0.3, save as negative samples\n",
    "                    for i in range(10):\n",
    "                        size = randint(12, min(w, h) / 2)\n",
    "                        delta_x = randint(max(-size, -x1), w1)\n",
    "                        delta_y = randint(max(-size, -y1), h1)\n",
    "                        nx1 = int(max(0, x1 + delta_x))\n",
    "                        ny1 = int(max(0, y1 + delta_y))\n",
    "                        if((nx1 + size > w1)|(ny1 + size > h1)):\n",
    "                            continue\n",
    "                        if(np.max(IoU(np.array([nx1,ny1,nx1+size,ny1+size]),np.array(boxes)))<0.3):\n",
    "                            resized_img = cv2.resize(img[y:y+size,x:x+size,:], (12, 12))\n",
    "                            cv2.imwrite(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)),resized_img)\n",
    "                            f2.write(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)) + ' 0\\n')\n",
    "                            neg_idx=neg_idx+1\n",
    "                    #save num positive&part face whose IoU more than 0.65||0.4         \n",
    "                    box_ = np.array(box).reshape(1, -1)\n",
    "                    for i in range(10):\n",
    "                        size=randint(np.floor(0.8*min(w1,h1)),np.ceil(1.25*max(w1,h1))+1)\n",
    "                    \n",
    "                        delta_w = randint(-w1 * 0.2, w1 * 0.2 + 1)\n",
    "                        delta_h = randint(-h1 * 0.2, h1 * 0.2 + 1)\n",
    "                        # random face box\n",
    "                        nx1 = int(max(x1 + w1 / 2 + delta_w - size / 2, 0))\n",
    "                        ny1 = int(max(y1 + h1 / 2 + delta_h - size / 2, 0))\n",
    "                        nx2 = nx1 + size\n",
    "                        ny2 = ny1 + size\n",
    "                        \n",
    "                        if( nx2 > w | ny2 > h):\n",
    "                            continue \n",
    "                            \n",
    "                        offset_x1 = (x1 - nx1) / float(size)\n",
    "                        offset_y1 = (y1 - ny1) / float(size)\n",
    "                        offset_x2 = (x1+w1 - nx2) / float(size)\n",
    "                        offset_y2 = (y1+h1 - ny2) / float(size)                                \n",
    "\n",
    "                        if(IoU(np.array([nx1,ny1,nx2,ny2]),box_)>0.65):                     \n",
    "                            resized_img = cv2.resize(img[ny1:ny2,nx1:nx2,:], (12, 12))\n",
    "                            cv2.imwrite(os.path.join(positive_dir,'pos_%d.jpg'%(pos_idx)),resized_img)\n",
    "                            f1.write(os.path.join(positive_dir,'pos_%d.jpg'%(pos_idx)) + ' 1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,offset_y1,offset_x2,offset_y2))\n",
    "                            pos_idx=pos_idx+1   \n",
    "                            \n",
    "                        elif(IoU(np.array([nx1,ny1,nx2,ny2]),box_)>0.4):\n",
    "                            resized_img = cv2.resize(img[ny1:ny2,nx1:nx2,:], (12, 12))\n",
    "                            cv2.imwrite(os.path.join(par_dir,'par_%d.jpg'%(par_idx)),resized_img)\n",
    "                            f3.write(os.path.join(par_dir,'par_%d.jpg'%(par_idx)) + ' -1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,offset_y1,offset_x2,offset_y2))                           \n",
    "                            par_idx=par_idx+1 \n",
    "    print(\"pics all done,neg_pics %d in total,pos_pics %d in total,par_pics %d in total\"%(neg_idx,pos_idx,par_idx))\n",
    "    \n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()  \n",
    "print(time.time()-begin)\n",
    "#6841.530851840973\n",
    "\n",
    "# Onet\n",
    "# pics all done,neg_pics 845040 in total,pos_pics 484670 in total,par_pics 708282 in total\n",
    "# 6949.557825803757"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_P12_landmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tool import IoU,flip\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import randint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "begin=time.time()\n",
    "\n",
    "lfw_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\"\n",
    "pic_spilt_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\trainImageList.txt\"\n",
    "landmark_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\12\\\\landmark\"\n",
    "save_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\12\"\n",
    "\n",
    "if not os.path.exists(landmark_dir):\n",
    "    os.makedirs(landmark_dir)\n",
    "    \n",
    "f4 = open(os.path.join(save_dir, 'land_12.txt'), 'w')\n",
    "\n",
    "with open(pic_spilt_dir) as filenames:\n",
    "    land_idx=0\n",
    "    for line in filenames:\n",
    "        img_list=[]\n",
    "        mark_list=[]\n",
    "        line=line.strip().split(' ')\n",
    "        img=cv2.imread(os.path.join(lfw_dir,line[0]))\n",
    "        box=(line[1],line[2],line[3],line[4])\n",
    "        box=[int(_) for _ in box]\n",
    "        #format of box is [x,x+w,y,y+h]\n",
    "        height,weight,channel=img.shape\n",
    "        landmark=np.zeros((5,2))\n",
    "        for i in range(5):\n",
    "            mark=(float(line[5+2*i]),float(line[5+2*i+1]))\n",
    "            landmark[i]=mark\n",
    "\n",
    "        facemark=np.zeros((5,2))\n",
    "        for i in range(5):\n",
    "            mark=((landmark[i][0]-box[0])/(box[1]-box[0]),(landmark[i][1]-box[2])/(box[3]-box[2]))\n",
    "            facemark[i]=mark\n",
    "        img_list.append(cv2.resize(img[box[2]:box[3],box[0]:box[1]], (12, 12)))  \n",
    "        mark_list.append(facemark.reshape(10))\n",
    "        \n",
    "        box_=[box[0],box[2],box[1],box[3]]\n",
    "        #format of box is [x,y,x+w,y+h]      \n",
    "        x1,y1,x2,y2=box_\n",
    "        w=x2-x1+1\n",
    "        h=y2-y1+1\n",
    "        \n",
    "        if((x1<0)|(y1<0)|(max(w,h)<40)|(min(w,h)<=5)): \n",
    "            continue          \n",
    "        num=25\n",
    "        while(num):\n",
    "            \n",
    "            size=randint(np.floor(0.8*min(w,h)),np.ceil(1.25*max(w,h))+1)\n",
    "            \n",
    "            delta_w = randint(-w * 0.2, w * 0.2 + 1)\n",
    "            delta_h = randint(-h * 0.2, h * 0.2 + 1)\n",
    "            # random face box\n",
    "            nx1 = int(max(x1 + w / 2 + delta_w - size / 2, 0))\n",
    "            ny1 = int(max(y1 + h / 2 + delta_h - size / 2, 0))\n",
    "            nx2 = nx1 + size\n",
    "            ny2 = ny1 + size \n",
    "\n",
    "            if( nx2 > weight | ny2 > height):\n",
    "                continue               \n",
    "            \n",
    "            _box=[x1,y1,w,h]\n",
    "            _box=np.array(_box).reshape(1,-1)     \n",
    "            if(IoU(np.array([nx1,ny1,nx2,ny2]),_box)>0.65): \n",
    "                facemark=np.zeros((5,2))\n",
    "                for i in range(5):\n",
    "                    mark=((landmark[i][0]-nx1)/size,(landmark[i][1]-ny1)/size)\n",
    "                    facemark[i]=mark  \n",
    "                img_list.append(cv2.resize(img[ny1:ny2,nx1:nx2,:], (12, 12)))  \n",
    "                mark_list.append(facemark.reshape(10))\n",
    "                              \n",
    "                #mirro\n",
    "                mirro_mark=facemark.copy()\n",
    "                if(random.choice([0,1])):\n",
    "                    img1,mirro_mark=flip(img[ny1:ny2,nx1:nx2,:],mirro_mark)\n",
    "                    img_list.append(cv2.resize(img1, (12, 12)))  \n",
    "                    mark_list.append(mirro_mark.reshape(10))  \n",
    "                    \n",
    "                num=num-1\n",
    "        for i in range(len(img_list)):\n",
    "            \n",
    "            if np.sum(np.where(mark_list[i] <= 0, 1, 0)) > 0:\n",
    "                continue\n",
    "\n",
    "            if np.sum(np.where(mark_list[i] >= 1, 1, 0)) > 0:\n",
    "                continue\n",
    "            \n",
    "            cv2.imwrite(os.path.join(landmark_dir,'land_%d.jpg'%(land_idx)),img_list[i])\n",
    "            mark=[str(_)for _ in mark_list[i]]\n",
    "            f4.write(os.path.join(landmark_dir,'land_%d.jpg'%(land_idx)) +' -2 '+' '.join(mark)+'\\n')\n",
    "            land_idx=land_idx+1\n",
    "\n",
    "f4.close()    \n",
    "print(time.time()-begin)\n",
    "# 1642.9541683197021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_P12_TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import cv2\n",
    "import random\n",
    "\n",
    "terms=['neg_12','pos_12','par_12','land_12']\n",
    "\n",
    "for term in terms:\n",
    "    \n",
    "    with tf.python_io.TFRecordWriter(\"C:\\\\Users\\\\friedhelm\\\\Desktop\\\\DATA\\\\12\\\\%s_train.tfrecords\"%(term)) as writer:\n",
    "        with open(r'C:\\Users\\friedhelm\\Desktop\\DATA\\12\\%s.txt'%(term)) as readlines:\n",
    "            readlines=[line.strip().split(' ') for line in readlines]\n",
    "            random.shuffle(readlines)\n",
    "            for line in readlines:\n",
    "                print(line[0])\n",
    "                img=cv2.imread(line[0].replace('/','\\\\'))\n",
    "                img_raw = img.tobytes()\n",
    "                label=int(line[1])\n",
    "                roi=[0.0]*4               \n",
    "                landmark=[0.0]*10\n",
    "                if(len(line)==6):    \n",
    "                    roi=[float(_) for _ in line[2:6]]   \n",
    "                if(len(line)==12):\n",
    "                    landmark=[float(_) for _ in line[2:12]]                  \n",
    "                example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "                    \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "                    \"roi\": tf.train.Feature(float_list=tf.train.FloatList(value=roi)),\n",
    "                    \"landmark\": tf.train.Feature(float_list=tf.train.FloatList(value=landmark)),\n",
    "                }))\n",
    "                writer.write(example.SerializeToString())  #序列化为字符串            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def read_single_tfrecord(addr,_batch_size,shape):\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([addr],shuffle=True)\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue) #返回文件名和文件\n",
    "\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                   features={\n",
    "                                   'img':tf.FixedLenFeature([],tf.string),\n",
    "                                   'label':tf.FixedLenFeature([],tf.int64),                                   \n",
    "                                   'roi':tf.FixedLenFeature([4],tf.float32),\n",
    "                                   'landmark':tf.FixedLenFeature([10],tf.float32),\n",
    "                                   })\n",
    "    img=tf.decode_raw(features['img'],tf.uint8)\n",
    "    label=tf.cast(features['label'],tf.int32)\n",
    "    roi=tf.cast(features['roi'],tf.float32)\n",
    "    landmark=tf.cast(features['landmark'],tf.float32)\n",
    "    img = tf.reshape(img, [shape,shape,3])     \n",
    "    #     img=img_preprocess(img)\n",
    "    min_after_dequeue = 10000\n",
    "    batch_size = _batch_size\n",
    "    capacity = min_after_dequeue + 10 * batch_size\n",
    "    image_batch, label_batch, roi_batch, landmark_batch = tf.train.shuffle_batch([img,label,roi,landmark], \n",
    "                                                        batch_size=batch_size, \n",
    "                                                        capacity=capacity, \n",
    "                                                        min_after_dequeue=min_after_dequeue,\n",
    "                                                        num_threads=7)  \n",
    "    \n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "    roi_batch = tf.reshape(roi_batch,[batch_size,4])\n",
    "    landmark_batch = tf.reshape(landmark_batch,[batch_size,10])\n",
    "    \n",
    "    return image_batch, label_batch, roi_batch, landmark_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_multi_tfrecords(addr,_batch_size,shape):\n",
    "    \n",
    "    pos_dir,part_dir,neg_dir,landmark_dir = addr\n",
    "    pos_batch_size,part_batch_size,neg_batch_size,landmark_batch_size = _batch_size   \n",
    "    \n",
    "    pos_image,pos_label,pos_roi,pos_landmark = read_single_tfrecord(pos_dir, pos_batch_size, shape)\n",
    "    part_image,part_label,part_roi,part_landmark = read_single_tfrecord(part_dir, part_batch_size, shape)\n",
    "    neg_image,neg_label,neg_roi,neg_landmark = read_single_tfrecord(neg_dir, neg_batch_size, shape)\n",
    "    landmark_image,landmark_label,landmark_roi,landmark_landmark = read_single_tfrecord(landmark_dir, landmark_batch_size, shape)\n",
    "\n",
    "    images = tf.concat([pos_image,part_image,neg_image,landmark_image], 0, name=\"concat/image\")\n",
    "    labels = tf.concat([pos_label,part_label,neg_label,landmark_label],0,name=\"concat/label\")\n",
    "    rois = tf.concat([pos_roi,part_roi,neg_roi,landmark_roi],0,name=\"concat/roi\")\n",
    "    landmarks = tf.concat([pos_landmark,part_landmark,neg_landmark,landmark_landmark],0,name=\"concat/landmark\")\n",
    "    \n",
    "    return images,labels,rois,landmarks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr=['C:\\\\Users\\\\friedhelm\\\\Desktop\\\\DATA\\\\12\\\\land_12_train.tfrecords',\n",
    "      'C:\\\\Users\\\\friedhelm\\\\Desktop\\\\DATA\\\\12\\\\neg_12_train.tfrecords',\n",
    "      'C:\\\\Users\\\\friedhelm\\\\Desktop\\\\DATA\\\\12\\\\pos_12_train.tfrecords',\n",
    "      'C:\\\\Users\\\\friedhelm\\\\Desktop\\\\DATA\\\\12\\\\par_12_train.tfrecords']\n",
    "_batch_size=[1,4,1,1]\n",
    "shape=12\n",
    "images,labels,rois,landmarks =read_multi_tfrecords(addr,_batch_size,shape)\n",
    "i=0\n",
    "with tf.Session() as sess:\n",
    "    sess.run((tf.global_variables_initializer(),\n",
    "              tf.local_variables_initializer()))\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess,coord=coord)    \n",
    "    while(1):\n",
    "        i=i+1\n",
    "        if(i%9==1):\n",
    "            print(sess.run([labels,rois,landmarks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P12_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelu(inputs):\n",
    "\n",
    "    with tf.variable_scope('prelu'):\n",
    "        alphas = tf.get_variable(\"alphas\", shape=inputs.get_shape()[-1], dtype=tf.float32, initializer=tf.constant_initializer(0.25))\n",
    "        pos = tf.nn.relu(inputs)\n",
    "        neg = alphas * (inputs-abs(inputs))*0.5\n",
    "    \n",
    "    return pos + neg\n",
    "\n",
    "def conv2d(_input,name,conv_size,conv_stride,bias_size,pad,activation='prelu'):\n",
    "    \n",
    "    regularizer=tf.contrib.layers.l2_regularizer(0.0005)\n",
    "    with tf.variable_scope(name):\n",
    "        weight=tf.get_variable('weight',conv_size,initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        bias=tf.get_variable('bias',bias_size,initializer=tf.constant_initializer(0.0))\n",
    "        weight_loss=regularizer(weight)\n",
    "        tf.add_to_collection('weight_loss',weight_loss)\n",
    "        conv=tf.nn.conv2d(_input,weight,strides=conv_stride,padding=pad)\n",
    "        he=tf.nn.bias_add(conv,bias)\n",
    "        relu=tf.cond(tf.equal(activation,'prelu'),lambda:prelu(he),lambda:tf.cond(tf.equal(activation,'softmax'),lambda:tf.nn.softmax(he),lambda:he))     \n",
    "    \n",
    "    return relu\n",
    "\n",
    "def pool(_input,name,kernal_size,kernal_stride,pad):\n",
    "    \n",
    "    with tf.variable_scope(name):  \n",
    "        pool=tf.nn.max_pool(_input,ksize=kernal_size,strides=kernal_stride,padding=pad)  \n",
    "        \n",
    "    return pool\n",
    "    \n",
    "def Pnet_model(x):\n",
    "    \n",
    "    conv_1=conv2d(x,'conv_1',[3,3,3,10],[1,1,1,1],[10],'VALID')\n",
    "    pool_1=pool(conv_1,'pool_1',[1,2,2,1],[1,2,2,1],'SAME')\n",
    "    conv_2=conv2d(pool_1,'conv_2',[3,3,10,16],[1,1,1,1],[16],'VALID')\n",
    "    conv_3=conv2d(conv_2,'conv_3',[3,3,16,32],[1,1,1,1],[32],'VALID')\n",
    "    \n",
    "    face_label=conv2d(conv_2,'face_label',[1,1,32,2],[1,1,1,1],[2],'VALID','softmax')\n",
    "    bounding_box=conv2d(conv_2,'bounding_box',[1,1,32,4],[1,1,1,1],[4],'VALID','None')\n",
    "    landmark_local=conv2d(conv_2,'landmark_local',[1,1,32,10],[1,1,1,1],[10],'VALID','None')        \n",
    "    \n",
    "    return face_label, bounding_box ,landmark_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_loss(pre_label,act_label):\n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.int64)\n",
    "    valid_label=tf.where(tf.less(label,0),zeros,label)\n",
    "    \n",
    "    size=tf.size(pre_label)\n",
    "    pre_label=tf.reshape(pre_label,(1,-1))\n",
    "    column=tf.range(0,size/2)*2\n",
    "    column_to_stay=column+valid_label\n",
    "    pre_label=tf.squeeze(tf.gather(pre_label,column_to_stay))\n",
    "    loss = -tf.log(pre_label+1e-10)    \n",
    "    \n",
    "    ones=tf.ones_like(label,dtype=tf.float32)\n",
    "    valid_colunm = tf.where(label < zeros,zeros,ones)  \n",
    "    \n",
    "    num_column=tf.reduce_sum(valid_colunm)\n",
    "    num=tf.cast(num_column*0.7,dtype=tf.int64)\n",
    "    loss=loss*valid_colunm\n",
    "    loss,_=tf.nn.top_k(loss,num)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "def box_los(label,pre_box,act_box) :    \n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.float32)\n",
    "    ones=tf.ones_like(label,dtype=tf.float32)    \n",
    "    valid_label=tf.where(tf.equal(abs(label),1),ones,zeros)\n",
    "    loss=tf.reduce_sum(tf.square(act_box-pre_box),axis=1)\n",
    "    loss=loss*valid_label\n",
    "    return tf.reduce_mean(loss)  \n",
    "    \n",
    "def landmark_los(label,landmark,_landmark):    \n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.float32)\n",
    "    ones = tf.ones_like(label,dtype=tf.float32)\n",
    "    valid_label=tf.where(tf.equal(label,-2),ones,zeros)\n",
    "    loss=tf.reduce_sum(tf.square(_landmark-landmark),axis=1)\n",
    "    loss=loss*valid_label\n",
    "    return tf.reduce_mean(loss)     \n",
    "    \n",
    "def cal_accuracy(cls_prob,label):\n",
    "\n",
    "    pred = tf.argmax(cls_prob,axis=1)\n",
    "    label_int = tf.cast(label,tf.int64)\n",
    "    cond = tf.where(tf.greater_equal(label_int,0))\n",
    "    picked = tf.squeeze(cond)\n",
    "    label_picked = tf.gather(label_int,picked)\n",
    "    pred_picked = tf.gather(pred,picked)\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(tf.equal(label_picked,pred_picked),tf.float32))\n",
    "    \n",
    "    return accuracy_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_P12model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from core.tool import read_multi_tfrecords\n",
    "from core.MTCNN_model import Pnet_model\n",
    "\n",
    "\n",
    "\n",
    "def image_color_distort(inputs):\n",
    "    inputs = tf.image.random_contrast(inputs, lower=0.5, upper=1.5)\n",
    "    inputs = tf.image.random_brightness(inputs, max_delta=0.2)\n",
    "    inputs = tf.image.random_hue(inputs,max_delta= 0.2)\n",
    "    inputs = tf.image.random_saturation(inputs,lower = 0.5, upper= 1.5)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def label_los(pre_label,act_label):\n",
    "    \n",
    "    ratio=tf.constant(0.7)\n",
    "    zeros=tf.zeros_like(act_label,dtype=tf.int32)\n",
    "    valid_label=tf.where(tf.less(act_label,0),zeros,act_label)\n",
    "\n",
    "    column_num=tf.shape(pre_label,out_type=tf.int32)[0]\n",
    "    pre_label=tf.squeeze(tf.reshape(pre_label,(1,-1)))\n",
    "    column=tf.range(0,column_num)*2 \n",
    "    column_to_stay=column+valid_label\n",
    "\n",
    "    pre_label=tf.squeeze(tf.gather(pre_label,column_to_stay))\n",
    "    loss = -tf.log(pre_label+1e-10)      \n",
    "    ones=tf.ones_like(act_label,dtype=tf.float32)\n",
    "    zero=tf.zeros_like(act_label,dtype=tf.float32)\n",
    "    valid_colunm = tf.where(act_label < zeros,zero,ones)  \n",
    "    \n",
    "    num_column=tf.reduce_sum(valid_colunm)\n",
    "    num=tf.cast(num_column*ratio,dtype=tf.int32)\n",
    "    loss=tf.multiply(loss,valid_colunm,'label_los')\n",
    "    loss,_=tf.nn.top_k(loss,num)\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "    \n",
    "def roi_los(label,pre_box,act_box) :    \n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.float32)\n",
    "    ones=tf.ones_like(label,dtype=tf.float32)    \n",
    "    valid_label=tf.where(tf.equal(abs(label),1),ones,zeros)\n",
    "    loss=tf.reduce_sum(tf.square(act_box-pre_box),axis=1)\n",
    "    loss=tf.multiply(loss,valid_label,'roi_los')\n",
    "    return tf.reduce_mean(loss) \n",
    "    \n",
    "def landmark_los(label,pre_landmark,act_landmark):    \n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.float32)\n",
    "    ones = tf.ones_like(label,dtype=tf.float32)\n",
    "    valid_label=tf.where(tf.equal(label,-2),ones,zeros)\n",
    "    loss=tf.reduce_sum(tf.square(act_landmark-pre_landmark),axis=1)\n",
    "    loss=tf.multiply(loss,valid_label,'landmark_los')\n",
    "    return tf.reduce_mean(loss)     \n",
    "    \n",
    "def cal_accuracy(cls_prob,label):\n",
    "       \n",
    "    pred = tf.argmax(cls_prob,axis=1)\n",
    "    label_int = tf.cast(label,tf.int64)\n",
    "    cond = tf.where(tf.greater_equal(label_int,0))\n",
    "    picked = tf.squeeze(cond)\n",
    "    label_picked = tf.gather(label_int,picked)\n",
    "    pred_picked = tf.gather(pred,picked)\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(tf.equal(label_picked,pred_picked),tf.float32))\n",
    "    \n",
    "    return accuracy_op\n",
    "\n",
    "def train(image,label,roi,landmark,model,model_name):\n",
    "    \n",
    "    _label, _roi ,_landmark=model(image)\n",
    "    \n",
    "    with tf.name_scope('output'):\n",
    "        _label=tf.squeeze(_label,name='label')\n",
    "        _roi=tf.squeeze(_roi,name='roi')\n",
    "        _landmark=tf.squeeze(_landmark,name='landmark')\n",
    "        \n",
    "    _label_los=label_los(_label,label)\n",
    "    _box_los=roi_los(label,_roi,roi)    \n",
    "    _landmark_los=landmark_los(label,_landmark,landmark)\n",
    "    \n",
    "    function_loss=_label_los+_box_los*0.5+_landmark_los*0.5\n",
    "\n",
    "    tf.add_to_collection(\"loss\", function_loss)\n",
    "    loss_all=tf.get_collection('loss')\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        loss=tf.reduce_sum(loss_all)\n",
    "        tf.summary.scalar('loss',loss) \n",
    "        \n",
    "    opt=tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        train_accuracy=cal_accuracy(_label,label)\n",
    "        tf.summary.scalar('accuracy',train_accuracy) \n",
    "\n",
    "    saver=tf.train.Saver()\n",
    "    merged=tf.summary.merge_all() \n",
    "    \n",
    "    images,labels,rois,landmarks=read_multi_tfrecords(addr,batch_size,img_size)   \n",
    "    images=image_color_distort(images)    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run((tf.global_variables_initializer(),\n",
    "                  tf.local_variables_initializer()))\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        image_batch,label_batch,roi_batch,landmark_batch=sess.run([images,labels,rois,landmarks])\n",
    "    \n",
    "        writer_train=tf.summary.FileWriter('C:\\\\Users\\\\312\\\\Desktop\\\\',sess.graph)\n",
    "        \n",
    "        for i in range(1,100001):\n",
    "            \n",
    "            image_batch,label_batch,roi_batch,landmark_batch=sess.run([images,labels,rois,landmarks])\n",
    "\n",
    "            sess.run(opt,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch})\n",
    "            if(i%100==0):\n",
    "                summary=sess.run(merged,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch})\n",
    "                writer_train.add_summary(summary,i) \n",
    "            if(i%1000==0):\n",
    "                print('次数',i)    \n",
    "                print('train_accuracy',sess.run(train_accuracy,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch}))\n",
    "                print('loss',sess.run(loss,{image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch}))               \n",
    "                print('time',time.time()-begin)\n",
    "                if(i%10000==0):\n",
    "                    saver.save(sess,\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\model\\\\%s.ckpt\"%(model_name),global_step=i)\n",
    "    writer_train.close()\n",
    "    \n",
    "def main(model,model_name):\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        image=tf.placeholder(tf.float32,name='image')\n",
    "        label=tf.placeholder(tf.int32,name='label')\n",
    "        roi=tf.placeholder(tf.float32,name='roi')\n",
    "        landmark = tf.placeholder(tf.float32,name='landmark')  \n",
    "\n",
    "    train(image,label,roi,landmark,model,model_name)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    img_size=12\n",
    "    batch=448\n",
    "    batch_size=[192,64,64,128]\n",
    "    addr=[\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\neg_%d_train.tfrecords\"%(img_size,img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\pos_%d_train.tfrecords\"%(img_size,img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\par_%d_train.tfrecords\"%(img_size,img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\land_%d_train.tfrecords\"%(img_size,img_size)]  \n",
    "        \n",
    "    model=Pnet_model\n",
    "    model_name=\"Pnet_model\"    \n",
    "    \n",
    "    begin=time.time()\n",
    "    \n",
    "    main(model,model_name)\n",
    "# tensorboard --logdir=C:\\\\Users\\\\312\\\\Desktop\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_R24_classify_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#159424张人脸\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from core.tool import IoU,NMS,featuremap\n",
    "import os\n",
    "\n",
    "begin=time.time()\n",
    "img_size=24\n",
    "map_shape=12\n",
    "stride=2\n",
    "factor=0.79\n",
    "threshold=0.8\n",
    "\n",
    "graph_path='E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\\\model\\\\Pnet_model.ckpt-60000.meta'\n",
    "model_path='E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\\\model\\\\Pnet_model.ckpt-60000'\n",
    "saver=tf.train.import_meta_graph(graph_path)\n",
    "\n",
    "WIDER_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\WIDER_train\\\\images\"\n",
    "WIDER_spilt_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\wider_face_split\\\\wider_face_train_bbx_gt.txt\"\n",
    "negative_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\negative\"%(img_size)\n",
    "positive_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\positive\"%(img_size)\n",
    "par_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\part\"%(img_size)\n",
    "save_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\"%(img_size)\n",
    "\n",
    "if not os.path.exists(positive_dir):\n",
    "    os.makedirs(positive_dir)\n",
    "if not os.path.exists(par_dir):\n",
    "    os.makedirs(par_dir)\n",
    "if not os.path.exists(negative_dir):\n",
    "    os.makedirs(negative_dir)\n",
    "    \n",
    "f1 = open(os.path.join(save_dir, 'pos_%d.txt'%(img_size)), 'w')\n",
    "f2 = open(os.path.join(save_dir, 'neg_%d.txt'%(img_size)), 'w')\n",
    "f3 = open(os.path.join(save_dir, 'par_%d.txt'%(img_size)), 'w')   \n",
    "\n",
    "with tf.Session() as sess: \n",
    "    \n",
    "    saver.restore(sess,model_path)\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    with open(WIDER_spilt_dir) as filenames:\n",
    "        p=0\n",
    "        idx=0\n",
    "        neg_idx=0\n",
    "        pos_idx=0\n",
    "        par_idx=0\n",
    "        for line in filenames.readlines():\n",
    "            line=line.strip().split(' ')\n",
    "            if(p==0):\n",
    "                pic_dir=line[0]\n",
    "                p=1\n",
    "                boxes=[]\n",
    "            elif(p==1):\n",
    "                k=int(line[0])\n",
    "                p=2\n",
    "            elif(p==2):\n",
    "                b=[]            \n",
    "                k=k-1\n",
    "                if(k==0):\n",
    "                    p=0                \n",
    "                for i in range(4):\n",
    "                    b.append(int(line[i]))\n",
    "                boxes.append(b)\n",
    "                # format of boxes is [x,y,w,h]\n",
    "                if(p==0):\n",
    "                    img=cv2.imread(os.path.join(WIDER_dir,pic_dir).replace('/','\\\\'))\n",
    "                    h,w,c=img.shape\n",
    "                    print(pic_dir)\n",
    "                    if(min(h,w)<20):\n",
    "                        continue\n",
    "                        \n",
    "                    scales=[]\n",
    "                    total_box=[]\n",
    "#                     bounding_boxes=[]\n",
    "#                     NMS_box=[]\n",
    "                    small=min(img.shape[0:2])\n",
    "                    pro=12/20\n",
    "        \n",
    "                    while small>=20:\n",
    "                        scales.append(pro)\n",
    "                        pro*=factor\n",
    "                        small*=factor  \n",
    "\n",
    "                    for scale in scales:\n",
    "\n",
    "                        scale_img=cv2.resize(img,((int(img.shape[1]*scale)),(int(img.shape[0]*scale))))\n",
    "                        bounding_boxes=featuremap(sess,graph,scale_img,scale,map_shape,stride,threshold)\n",
    "\n",
    "                        if(bounding_boxes):\n",
    "                            for box in bounding_boxes:\n",
    "                                total_box.append(box)\n",
    "                                                  \n",
    "                    NMS_box=NMS(total_box)\n",
    "                    neg_num=0\n",
    "                    for box_ in NMS_box:\n",
    "                        \n",
    "                        box=box_.copy()                        \n",
    "                        if((box[0]<0)|(box[1]<0)|(box[2]>w)|(box[3]>h)|(box[2]-box[0]<=20)|(box[3]-box[1]<=20)): \n",
    "                            continue  \n",
    "                        # format of total_box: [x1,y1,x2,y2,score,offset_x1,offset_y1,offset_x2,offset_y2,10*landmark]  \n",
    "                        \n",
    "                        t_box=[0]*4\n",
    "                        t_w=box[2]-box[0]+1\n",
    "                        t_h=box[3]-box[1]+1\n",
    "                        \n",
    "                        t_box[0]=box[5]*t_w+box[0]\n",
    "                        t_box[1]=box[6]*t_h+box[1]                     \n",
    "                        t_box[2]=box[7]*t_w+box[2]    \n",
    "                        t_box[3]=box[8]*t_h+box[3]                        \n",
    "                        # 计算真实人脸框\n",
    "                        \n",
    "                        if((t_box[0]<0)|(t_box[1]<0)|(t_box[2]>img.shape[1])|(t_box[3]>img.shape[0])|(t_box[2]-t_box[0]<=20)|(t_box[3]-t_box[1]<=20)): \n",
    "                            continue \n",
    "                            \n",
    "                        ti_box=t_box.copy()\n",
    "                        ti_box=[int(_) for _ in ti_box]\n",
    "                        \n",
    "                        Iou=IoU(np.array(t_box),np.array(boxes))\n",
    "                        \n",
    "                        if((np.max(Iou)<0.3)&(neg_num<60)):\n",
    "                            resized_img = cv2.resize(img[ti_box[1]:ti_box[3],ti_box[0]:ti_box[2],:], (img_size,img_size))\n",
    "                            cv2.imwrite(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)),resized_img)\n",
    "                            f2.write(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)) + ' 0\\n')\n",
    "                            neg_idx=neg_idx+1\n",
    "                            neg_num=neg_num+1\n",
    "                        \n",
    "                        else:\n",
    "                            x1,y1,w1,h1=boxes[np.argmax(Iou)]\n",
    "                            \n",
    "                            offset_x1 = (x1 - t_box[0]) / float(t_box[2]-t_box[0]+1)\n",
    "                            offset_y1 = (y1 - t_box[1]) / float(t_box[3]-t_box[1]+1)\n",
    "                            offset_x2 = (x1+w1 - t_box[2]) / float(t_box[2]-t_box[0]+1)\n",
    "                            offset_y2 = (y1+h1 - t_box[3]) / float(t_box[3]-t_box[1]+1)                         \n",
    "                            \n",
    "                            if(np.max(Iou)>0.65):                    \n",
    "                                resized_img = cv2.resize(img[ti_box[1]:ti_box[3],ti_box[0]:ti_box[2],:], (img_size, img_size))\n",
    "                                cv2.imwrite(os.path.join(positive_dir,'pos_%d.jpg'%(pos_idx)),resized_img)\n",
    "                                f1.write(os.path.join(positive_dir,'pos_%d.jpg'%(pos_idx)) + ' 1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,offset_y1,offset_x2,offset_y2))\n",
    "                                pos_idx=pos_idx+1   \n",
    "\n",
    "                            elif(np.max(Iou)>0.4):\n",
    "                                resized_img = cv2.resize(img[ti_box[1]:ti_box[3],ti_box[0]:ti_box[2],:], (img_size, img_size))\n",
    "                                cv2.imwrite(os.path.join(par_dir,'par_%d.jpg'%(par_idx)),resized_img)\n",
    "                                f3.write(os.path.join(par_dir,'par_%d.jpg'%(par_idx)) + ' -1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,offset_y1,offset_x2,offset_y2))                           \n",
    "                                par_idx=par_idx+1 \n",
    "                    idx+=1\n",
    "                    if(idx%100==0):\n",
    "                        print('idx: ',idx,\" ;neg_idx: \",neg_idx,\" ;pos_idx: \",pos_idx,\" ;par_idx: \",par_idx)\n",
    "                        print(time.time()-begin)\n",
    "    print(\"pics all done,neg_pics %d in total,pos_pics %d in total,par_pics %d in total\"%(neg_idx,pos_idx,par_idx))\n",
    "    \n",
    "f1.close()\n",
    "f2.close()\n",
    "f3.close()  \n",
    "print(time.time()-begin)\n",
    "\n",
    "#pics all done,neg_pics 758503 in total,pos_pics 285017 in total,par_pics 572771 in total\n",
    "# 17590.795156002045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_R24_landmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tool import IoU,flip\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import randint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    \n",
    "    f4 = open(os.path.join(save_dir, 'land_%d.txt'%(img_size)), 'w')\n",
    "\n",
    "    with open(pic_spilt_dir) as filenames:\n",
    "        land_idx=0\n",
    "        for line in filenames:\n",
    "            img_list=[]\n",
    "            mark_list=[]\n",
    "            line=line.strip().split(' ')\n",
    "            img=cv2.imread(os.path.join(lfw_dir,line[0]))\n",
    "            box=(line[1],line[2],line[3],line[4])\n",
    "            box=[int(_) for _ in box]\n",
    "            #format of box is [x,x+w,y,y+h]\n",
    "            height,weight,channel=img.shape\n",
    "            landmark=np.zeros((5,2))\n",
    "            for i in range(5):\n",
    "                mark=(float(line[5+2*i]),float(line[5+2*i+1]))\n",
    "                landmark[i]=mark\n",
    "\n",
    "            facemark=np.zeros((5,2))\n",
    "            for i in range(5):\n",
    "                mark=((landmark[i][0]-box[0])/(box[1]-box[0]),(landmark[i][1]-box[2])/(box[3]-box[2]))\n",
    "                facemark[i]=mark\n",
    "            img_list.append(cv2.resize(img[box[2]:box[3],box[0]:box[1]], (img_size, img_size)))  \n",
    "            mark_list.append(facemark.reshape(10))\n",
    "\n",
    "            box_=[box[0],box[2],box[1],box[3]]\n",
    "            #format of box is [x,y,x+w,y+h]      \n",
    "            x1,y1,x2,y2=box_\n",
    "            w=x2-x1+1\n",
    "            h=y2-y1+1\n",
    "\n",
    "            if((x1<0)|(y1<0)|(max(w,h)<40)|(min(w,h)<=5)): \n",
    "                continue          \n",
    "            num=40\n",
    "            while(num):\n",
    "\n",
    "                size=randint(np.floor(0.8*min(w,h)),np.ceil(1.25*max(w,h))+1)\n",
    "\n",
    "                delta_w = randint(-w * 0.2, w * 0.2 + 1)\n",
    "                delta_h = randint(-h * 0.2, h * 0.2 + 1)\n",
    "                # random face box\n",
    "                nx1 = int(max(x1 + w / 2 + delta_w - size / 2, 0))\n",
    "                ny1 = int(max(y1 + h / 2 + delta_h - size / 2, 0))\n",
    "                nx2 = nx1 + size\n",
    "                ny2 = ny1 + size \n",
    "\n",
    "                if( nx2 > weight | ny2 > height):\n",
    "                    continue               \n",
    "\n",
    "                _box=[x1,y1,w,h]\n",
    "                _box=np.array(_box).reshape(1,-1)     \n",
    "                if(IoU(np.array([nx1,ny1,nx2,ny2]),_box)>0.65): \n",
    "                    facemark=np.zeros((5,2))\n",
    "                    for i in range(5):\n",
    "                        mark=((landmark[i][0]-nx1)/size,(landmark[i][1]-ny1)/size)\n",
    "                        facemark[i]=mark  \n",
    "                    img_list.append(cv2.resize(img[ny1:ny2,nx1:nx2,:], (img_size, img_size)))  \n",
    "                    mark_list.append(facemark.reshape(10))\n",
    "\n",
    "                    #mirro\n",
    "                    mirro_mark=facemark.copy()\n",
    "                    if(random.choice([0,1])):\n",
    "                        img1,mirro_mark=flip(img[ny1:ny2,nx1:nx2,:],mirro_mark)\n",
    "                        img_list.append(cv2.resize(img1, (img_size, img_size)))  \n",
    "                        mark_list.append(mirro_mark.reshape(10))  \n",
    "\n",
    "                    num=num-1\n",
    "            for i in range(len(img_list)):\n",
    "\n",
    "                if np.sum(np.where(mark_list[i] <= 0, 1, 0)) > 0:\n",
    "                    continue\n",
    "\n",
    "                if np.sum(np.where(mark_list[i] >= 1, 1, 0)) > 0:\n",
    "                    continue\n",
    "\n",
    "                cv2.imwrite(os.path.join(landmark_dir,'land_%d.jpg'%(land_idx)),img_list[i])\n",
    "                mark=[str(_)for _ in mark_list[i]]\n",
    "                f4.write(os.path.join(landmark_dir,'land_%d.jpg'%(land_idx)) +' -2 '+' '.join(mark)+'\\n')\n",
    "                land_idx=land_idx+1\n",
    "\n",
    "    f4.close()    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    img_size=24\n",
    "    \n",
    "    #change img_size to P R O net\n",
    "    begin=time.time()\n",
    "\n",
    "    lfw_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\"\n",
    "    pic_spilt_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\trainImageList.txt\"\n",
    "    landmark_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\landmark\"%(img_size)\n",
    "    save_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\"%(img_size)\n",
    "\n",
    "    if not os.path.exists(landmark_dir):\n",
    "        os.makedirs(landmark_dir)    \n",
    "\n",
    "    main()\n",
    "    \n",
    "    print(time.time()-begin)\n",
    "    \n",
    "#R_net 2320.5425374507904\n",
    "#O_net 3131.904032945633"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_R24_TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    \n",
    "    for index,term in enumerate(terms):\n",
    "        num=0\n",
    "        print(\"%s start\"%(term))\n",
    "        with tf.python_io.TFRecordWriter(\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\%s_train.tfrecords\"%(img_size,term)) as writer:\n",
    "            with open(r'E:\\friedhelm\\object\\face_detection_MTCNN\\DATA\\%d\\%s.txt'%(img_size,term)) as readlines:\n",
    "                readlines=[line.strip().split(' ') for line in readlines]\n",
    "                random.shuffle(readlines)\n",
    "                for i,line in enumerate(readlines):\n",
    "                    if(i%50000==0):\n",
    "                        print(i)\n",
    "                    img=cv2.imread(line[0].replace('/','\\\\'))\n",
    "                    img_raw = img.tobytes()\n",
    "                    label=int(line[1])\n",
    "                    roi=[0.0]*4               \n",
    "                    landmark=[0.0]*10\n",
    "                    if(len(line)==6):    \n",
    "                        roi=[float(_) for _ in line[2:6]]   \n",
    "                    if(len(line)==12):\n",
    "                        landmark=[float(_) for _ in line[2:12]]                  \n",
    "                    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "                        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "                        \"roi\": tf.train.Feature(float_list=tf.train.FloatList(value=roi)),\n",
    "                        \"landmark\": tf.train.Feature(float_list=tf.train.FloatList(value=landmark)),\n",
    "                    }))\n",
    "                    writer.write(example.SerializeToString())  #序列化为字符串  \n",
    "                    num+=1\n",
    "                    if(num==base*scale[index]):\n",
    "                        print(\"%s finish\"%(term))\n",
    "                        break\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    img_size=24\n",
    "    #change img_size to P R O net\n",
    "    terms=['neg_%d'%(img_size),'pos_%d'%(img_size),'par_%d'%(img_size),'land_%d'%(img_size)]\n",
    "    scale=[3,1,1,2]\n",
    "    base=200000\n",
    "\n",
    "    begin=time.time()\n",
    "\n",
    "    main()\n",
    "    \n",
    "    print(time.time()-begin)\n",
    "\n",
    "#Pnet train_data               \n",
    "#neg 645017\n",
    "#par 507206\n",
    "#pos 285560 \n",
    "#land 584332\n",
    "    \n",
    "#Rnet train_data neg_pics 758503 in total,pos_pics 285017 in total,par_pics 572771 in total land \n",
    "\n",
    "#29951.208035707474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_R24model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from core.tool import read_multi_tfrecords\n",
    "from MTCNN_model import Pnet_model,Rnet_model,Onet_model\n",
    "import os\n",
    "\n",
    "def image_color_distort(inputs):\n",
    "    inputs = tf.image.random_contrast(inputs, lower=0.5, upper=1.5)\n",
    "    inputs = tf.image.random_brightness(inputs, max_delta=0.2)\n",
    "    inputs = tf.image.random_hue(inputs,max_delta= 0.2)\n",
    "    inputs = tf.image.random_saturation(inputs,lower = 0.5, upper= 1.5)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def label_los(pre_label,act_label):\n",
    "    \n",
    "    ratio=tf.constant(0.7)\n",
    "    zeros=tf.zeros_like(act_label,dtype=tf.int32)\n",
    "    valid_label=tf.where(tf.less(act_label,0),zeros,act_label)\n",
    "\n",
    "    column_num=tf.shape(pre_label,out_type=tf.int32)[0]\n",
    "    pre_label=tf.squeeze(tf.reshape(pre_label,(1,-1)))\n",
    "    column=tf.range(0,column_num)*2 \n",
    "    column_to_stay=column+valid_label\n",
    "\n",
    "    pre_label=tf.squeeze(tf.gather(pre_label,column_to_stay))\n",
    "    loss = -tf.log(pre_label+1e-10)      \n",
    "    ones=tf.ones_like(act_label,dtype=tf.float32)\n",
    "    zero=tf.zeros_like(act_label,dtype=tf.float32)\n",
    "    valid_colunm = tf.where(act_label < zeros,zero,ones)  \n",
    "    \n",
    "    num_column=tf.reduce_sum(valid_colunm)\n",
    "    num=tf.cast(num_column*ratio,dtype=tf.int32)\n",
    "    loss=tf.multiply(loss,valid_colunm,'label_los')\n",
    "    loss,_=tf.nn.top_k(loss,num)\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "    \n",
    "def roi_los(label,pre_box,act_box) :    \n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.float32)\n",
    "    ones=tf.ones_like(label,dtype=tf.float32)    \n",
    "    valid_label=tf.where(tf.equal(abs(label),1),ones,zeros)\n",
    "    loss=tf.reduce_sum(tf.square(act_box-pre_box),axis=1)\n",
    "    loss=tf.multiply(loss,valid_label,'roi_los')\n",
    "    return tf.reduce_mean(loss) \n",
    "    \n",
    "def landmark_los(label,pre_landmark,act_landmark):    \n",
    "    \n",
    "    zeros=tf.zeros_like(label,dtype=tf.float32)\n",
    "    ones = tf.ones_like(label,dtype=tf.float32)\n",
    "    valid_label=tf.where(tf.equal(label,-2),ones,zeros)\n",
    "    loss=tf.reduce_sum(tf.square(act_landmark-pre_landmark),axis=1)\n",
    "    loss=tf.multiply(loss,valid_label,'landmark_los')\n",
    "    return tf.reduce_mean(loss)     \n",
    "    \n",
    "def cal_accuracy(cls_prob,label):\n",
    "       \n",
    "    pred = tf.argmax(cls_prob,axis=1)\n",
    "    label_int = tf.cast(label,tf.int64)\n",
    "    cond = tf.where(tf.greater_equal(label_int,0))\n",
    "    picked = tf.squeeze(cond)\n",
    "    label_picked = tf.gather(label_int,picked)\n",
    "    pred_picked = tf.gather(pred,picked)\n",
    "    accuracy_op = tf.reduce_mean(tf.cast(tf.equal(label_picked,pred_picked),tf.float32))\n",
    "    \n",
    "    return accuracy_op\n",
    "\n",
    "def train(image,label,roi,landmark,model,model_name):\n",
    "    \n",
    "    _label, _roi ,_landmark=model(image)\n",
    "    \n",
    "    with tf.name_scope('output'):\n",
    "        _label=tf.squeeze(_label,name='label')\n",
    "        _roi=tf.squeeze(_roi,name='roi')\n",
    "        _landmark=tf.squeeze(_landmark,name='landmark')\n",
    "        \n",
    "    _label_los=label_los(_label,label)\n",
    "    _box_los=roi_los(label,_roi,roi)    \n",
    "    _landmark_los=landmark_los(label,_landmark,landmark)\n",
    "    \n",
    "    function_loss=_label_los*ratio[0]+_box_los*ratio[1]+_landmark_los*ratio[2]\n",
    "\n",
    "    tf.add_to_collection(\"loss\", function_loss)\n",
    "    loss_all=tf.get_collection('loss')\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        loss=tf.reduce_sum(loss_all)\n",
    "        tf.summary.scalar('loss',loss) \n",
    "        \n",
    "    opt=tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        train_accuracy=cal_accuracy(_label,label)\n",
    "        tf.summary.scalar('accuracy',train_accuracy) \n",
    "\n",
    "    saver=tf.train.Saver()\n",
    "    merged=tf.summary.merge_all() \n",
    "    \n",
    "    images,labels,rois,landmarks=read_multi_tfrecords(addr,batch_size,img_size)   \n",
    "    images=image_color_distort(images)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run((tf.global_variables_initializer(),\n",
    "                  tf.local_variables_initializer()))\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        image_batch,label_batch,roi_batch,landmark_batch=sess.run([images,labels,rois,landmarks])\n",
    "        \n",
    "        writer_train=tf.summary.FileWriter('C:\\\\Users\\\\312\\\\Desktop\\\\',sess.graph)\n",
    "        try:\n",
    "            \n",
    "            for i in range(1,train_step):\n",
    "                \n",
    "                image_batch,label_batch,roi_batch,landmark_batch=sess.run([images,labels,rois,landmarks])\n",
    "                \n",
    "                sess.run(opt,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch})\n",
    "                if(i%100==0):\n",
    "                    summary=sess.run(merged,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch})\n",
    "                    writer_train.add_summary(summary,i) \n",
    "                if(i%1000==0):\n",
    "                    print('次数',i)    \n",
    "                    print('train_accuracy',sess.run(train_accuracy,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch}))\n",
    "                    print('loss',sess.run(loss,{image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch}))               \n",
    "                    print('time',time.time()-begin)\n",
    "                    if(i%10000==0):\n",
    "                        saver.save(sess,\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\%s\\\\%s_%d.ckpt\"%(model_name,model_name,i))\n",
    "        except  tf.errors.OutOfRangeError:\n",
    "            print(\"finished\")\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            writer_train.close()\n",
    "        coord.join(threads)\n",
    "    \n",
    "def main(model):\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        image=tf.placeholder(tf.float32,name='image')\n",
    "        label=tf.placeholder(tf.int32,name='label')\n",
    "        roi=tf.placeholder(tf.float32,name='roi')\n",
    "        landmark = tf.placeholder(tf.float32,name='landmark')  \n",
    "\n",
    "    train(image,label,roi,landmark,model,model_name)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    img_size=24\n",
    "    batch=448\n",
    "    batch_size=[192,64,64,128]\n",
    "    addr=[\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\neg_%d_train.tfrecords\"%(img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\pos_%d_train.tfrecords\"%(img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\par_%d_train.tfrecords\"%(img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\land_%d_train.tfrecords\"%(img_size)]  \n",
    "\n",
    "    model=Rnet_model\n",
    "    model_name=\"Rnet_model\"    \n",
    "    train_step=100001\n",
    "    learning_rate=0.001\n",
    "    \n",
    "    save_model_path=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\%s\"%(model_name)\n",
    "    \n",
    "    if not os.path.exists(save_model_path):\n",
    "        os.makedirs(save_model_path) \n",
    "        \n",
    "    if(model_name==\"Onet_model\"):\n",
    "        ratio=[1,0.5,1]\n",
    "    else:\n",
    "        ratio=[1,0.5,0.5]\n",
    "    \n",
    "\n",
    "    begin=time.time()        \n",
    "    main(model)\n",
    "# tensorboard --logdir=C:\\\\Users\\\\312\\\\Desktop\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_O48_classify_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tool import IoU\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def main():\n",
    "\n",
    "    f1 = open(os.path.join(save_dir, 'pos_%d.txt'%(img_size)), 'w')\n",
    "    f2 = open(os.path.join(save_dir, 'neg_%d.txt'%(img_size)), 'w')\n",
    "    f3 = open(os.path.join(save_dir, 'par_%d.txt'%(img_size)), 'w')    \n",
    "    \n",
    "    with open(WIDER_spilt_dir) as filenames:\n",
    "        p=0\n",
    "        neg_idx=0\n",
    "        pos_idx=0\n",
    "        par_idx=0\n",
    "        for line in filenames.readlines():\n",
    "            line=line.strip().split(' ')\n",
    "            if(p==0):\n",
    "                pic_dir=line[0]\n",
    "                p=1\n",
    "                boxes=[]\n",
    "            elif(p==1):\n",
    "                k=int(line[0])\n",
    "                p=2\n",
    "            elif(p==2):\n",
    "                b=[]            \n",
    "                k=k-1\n",
    "                if(k==0):\n",
    "                    p=0                \n",
    "                for i in range(4):\n",
    "                    b.append(int(line[i]))\n",
    "                boxes.append(b)\n",
    "                # format of boxes is [x,y,w,h]\n",
    "                if(p==0):\n",
    "                    img=cv2.imread(os.path.join(WIDER_dir,pic_dir).replace('/','\\\\'))\n",
    "                    h,w,c=img.shape\n",
    "                    \n",
    "                    #save num negative pics whose IoU less than 0.3\n",
    "                    num=50\n",
    "                    while(num):\n",
    "                        size=randint(12,min(w,h)/2)\n",
    "                        x=randint(0,w-size)\n",
    "                        y=randint(0,h-size)\n",
    "                        if(np.max(IoU(np.array([x,y,x+size,y+size]),np.array(boxes)))<0.3):\n",
    "                            resized_img = cv2.resize(img[y:y+size,x:x+size,:], (img_size, img_size))\n",
    "                            cv2.imwrite(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)),resized_img)\n",
    "                            f2.write(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)) + ' 0\\n')\n",
    "                            neg_idx=neg_idx+1\n",
    "                            num=num-1       \n",
    "\n",
    "                    for box in boxes:\n",
    "                        if((box[0]<0)|(box[1]<0)|(max(box[2],box[3])<20)|(min(box[2],box[3])<=5)): \n",
    "                            continue  \n",
    "                        x1, y1, w1, h1 = box\n",
    "                        \n",
    "                        # crop images near the bounding box if IoU less than 0.3, save as negative samples\n",
    "                        for i in range(10):\n",
    "                            size = randint(12, min(w, h) / 2)\n",
    "                            delta_x = randint(max(-size, -x1), w1)\n",
    "                            delta_y = randint(max(-size, -y1), h1)\n",
    "                            nx1 = int(max(0, x1 + delta_x))\n",
    "                            ny1 = int(max(0, y1 + delta_y))\n",
    "                            if((nx1 + size > w1)|(ny1 + size > h1)):\n",
    "                                continue\n",
    "                            if(np.max(IoU(np.array([nx1,ny1,nx1+size,ny1+size]),np.array(boxes)))<0.3):\n",
    "                                resized_img = cv2.resize(img[y:y+size,x:x+size,:], (img_size, img_size))\n",
    "                                cv2.imwrite(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)),resized_img)\n",
    "                                f2.write(os.path.join(negative_dir,'neg_%d.jpg'%(neg_idx)) + ' 0\\n')\n",
    "                                neg_idx=neg_idx+1\n",
    "                                \n",
    "                        #save num positive&part face whose IoU more than 0.65|0.4         \n",
    "                        box_ = np.array(box).reshape(1, -1)\n",
    "                        for i in range(10):\n",
    "                            size=randint(np.floor(0.8*min(w1,h1)),np.ceil(1.25*max(w1,h1))+1)\n",
    "                        \n",
    "                            delta_w = randint(-w1 * 0.2, w1 * 0.2 + 1)\n",
    "                            delta_h = randint(-h1 * 0.2, h1 * 0.2 + 1)\n",
    "                            # random face box\n",
    "                            nx1 = int(max(x1 + w1 / 2 + delta_w - size / 2, 0))\n",
    "                            ny1 = int(max(y1 + h1 / 2 + delta_h - size / 2, 0))\n",
    "                            nx2 = nx1 + size\n",
    "                            ny2 = ny1 + size\n",
    "                            \n",
    "                            if( nx2 > w | ny2 > h):\n",
    "                                continue \n",
    "                                \n",
    "                            offset_x1 = (x1 - nx1) / float(size)\n",
    "                            offset_y1 = (y1 - ny1) / float(size)\n",
    "                            offset_x2 = (x1+w1 - nx2) / float(size)\n",
    "                            offset_y2 = (y1+h1 - ny2) / float(size)                                \n",
    "    \n",
    "                            if(IoU(np.array([nx1,ny1,nx2,ny2]),box_)>0.65):                     \n",
    "                                resized_img = cv2.resize(img[ny1:ny2,nx1:nx2,:], (img_size, img_size))\n",
    "                                cv2.imwrite(os.path.join(positive_dir,'pos_%d.jpg'%(pos_idx)),resized_img)\n",
    "                                f1.write(os.path.join(positive_dir,'pos_%d.jpg'%(pos_idx)) + ' 1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,offset_y1,offset_x2,offset_y2))\n",
    "                                pos_idx=pos_idx+1   \n",
    "                                \n",
    "                            elif(IoU(np.array([nx1,ny1,nx2,ny2]),box_)>0.4):\n",
    "                                resized_img = cv2.resize(img[ny1:ny2,nx1:nx2,:], (img_size, img_size))\n",
    "                                cv2.imwrite(os.path.join(par_dir,'par_%d.jpg'%(par_idx)),resized_img)\n",
    "                                f3.write(os.path.join(par_dir,'par_%d.jpg'%(par_idx)) + ' -1 %.2f %.2f %.2f %.2f\\n'%(offset_x1,offset_y1,offset_x2,offset_y2))                           \n",
    "                                par_idx=par_idx+1 \n",
    "        print(\"pics all done,neg_pics %d in total,pos_pics %d in total,par_pics %d in total\"%(neg_idx,pos_idx,par_idx))\n",
    "        \n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    f3.close()  \n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    img_size=48\n",
    "    \n",
    "    WIDER_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\WIDER_train\\\\images\"\n",
    "    WIDER_spilt_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\wider_face_split\\\\wider_face_train_bbx_gt.txt\"\n",
    "    negative_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\negative\"%(img_size)\n",
    "    positive_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\positive\"%(img_size)\n",
    "    par_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\part\"%(img_size)\n",
    "    save_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\"%(img_size)\n",
    "    \n",
    "    if not os.path.exists(positive_dir):\n",
    "        os.makedirs(positive_dir)\n",
    "    if not os.path.exists(par_dir):\n",
    "        os.makedirs(par_dir)\n",
    "    if not os.path.exists(negative_dir):\n",
    "        os.makedirs(negative_dir) \n",
    "        \n",
    "    begin=time.time()\n",
    "    \n",
    "    main()\n",
    "\n",
    "    print(time.time()-begin)\n",
    "#6841.530851840973"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_O48_landmark_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.tool import IoU,flip\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import randint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    \n",
    "    f4 = open(os.path.join(save_dir, 'land_%d.txt'%(img_size)), 'w')\n",
    "\n",
    "    with open(pic_spilt_dir) as filenames:\n",
    "        land_idx=0\n",
    "        for line in filenames:\n",
    "            img_list=[]\n",
    "            mark_list=[]\n",
    "            line=line.strip().split(' ')\n",
    "            img=cv2.imread(os.path.join(lfw_dir,line[0]))\n",
    "            box=(line[1],line[2],line[3],line[4])\n",
    "            box=[int(_) for _ in box]\n",
    "            #format of box is [x,x+w,y,y+h]\n",
    "            height,weight,channel=img.shape\n",
    "            landmark=np.zeros((5,2))\n",
    "            for i in range(5):\n",
    "                mark=(float(line[5+2*i]),float(line[5+2*i+1]))\n",
    "                landmark[i]=mark\n",
    "\n",
    "            facemark=np.zeros((5,2))\n",
    "            for i in range(5):\n",
    "                mark=((landmark[i][0]-box[0])/(box[1]-box[0]),(landmark[i][1]-box[2])/(box[3]-box[2]))\n",
    "                facemark[i]=mark\n",
    "            img_list.append(cv2.resize(img[box[2]:box[3],box[0]:box[1]], (img_size, img_size)))  \n",
    "            mark_list.append(facemark.reshape(10))\n",
    "\n",
    "            box_=[box[0],box[2],box[1],box[3]]\n",
    "            #format of box is [x,y,x+w,y+h]      \n",
    "            x1,y1,x2,y2=box_\n",
    "            w=x2-x1+1\n",
    "            h=y2-y1+1\n",
    "\n",
    "            if((x1<0)|(y1<0)|(max(w,h)<40)|(min(w,h)<=5)): \n",
    "                continue          \n",
    "            num=40\n",
    "            while(num):\n",
    "\n",
    "                size=randint(np.floor(0.8*min(w,h)),np.ceil(1.25*max(w,h))+1)\n",
    "\n",
    "                delta_w = randint(-w * 0.2, w * 0.2 + 1)\n",
    "                delta_h = randint(-h * 0.2, h * 0.2 + 1)\n",
    "                # random face box\n",
    "                nx1 = int(max(x1 + w / 2 + delta_w - size / 2, 0))\n",
    "                ny1 = int(max(y1 + h / 2 + delta_h - size / 2, 0))\n",
    "                nx2 = nx1 + size\n",
    "                ny2 = ny1 + size \n",
    "\n",
    "                if( nx2 > weight | ny2 > height):\n",
    "                    continue               \n",
    "\n",
    "                _box=[x1,y1,w,h]\n",
    "                _box=np.array(_box).reshape(1,-1)     \n",
    "                if(IoU(np.array([nx1,ny1,nx2,ny2]),_box)>0.65): \n",
    "                    facemark=np.zeros((5,2))\n",
    "                    for i in range(5):\n",
    "                        mark=((landmark[i][0]-nx1)/size,(landmark[i][1]-ny1)/size)\n",
    "                        facemark[i]=mark  \n",
    "                    img_list.append(cv2.resize(img[ny1:ny2,nx1:nx2,:], (img_size, img_size)))  \n",
    "                    mark_list.append(facemark.reshape(10))\n",
    "\n",
    "                    #mirro\n",
    "                    mirro_mark=facemark.copy()\n",
    "                    if(random.choice([0,1])):\n",
    "                        img1,mirro_mark=flip(img[ny1:ny2,nx1:nx2,:],mirro_mark)\n",
    "                        img_list.append(cv2.resize(img1, (img_size, img_size)))  \n",
    "                        mark_list.append(mirro_mark.reshape(10))  \n",
    "\n",
    "                    num=num-1\n",
    "            for i in range(len(img_list)):\n",
    "\n",
    "                if np.sum(np.where(mark_list[i] <= 0, 1, 0)) > 0:\n",
    "                    continue\n",
    "\n",
    "                if np.sum(np.where(mark_list[i] >= 1, 1, 0)) > 0:\n",
    "                    continue\n",
    "\n",
    "                cv2.imwrite(os.path.join(landmark_dir,'land_%d.jpg'%(land_idx)),img_list[i])\n",
    "                mark=[str(_)for _ in mark_list[i]]\n",
    "                f4.write(os.path.join(landmark_dir,'land_%d.jpg'%(land_idx)) +' -2 '+' '.join(mark)+'\\n')\n",
    "                land_idx=land_idx+1\n",
    "\n",
    "    f4.close()    \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    img_size=48\n",
    "    \n",
    "    #change img_size to P R O net\n",
    "    begin=time.time()\n",
    "\n",
    "    lfw_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\"\n",
    "    pic_spilt_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\prepare_data\\\\trainImageList.txt\"\n",
    "    landmark_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\landmark\"%(img_size)\n",
    "    save_dir=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\"%(img_size)\n",
    "\n",
    "    if not os.path.exists(landmark_dir):\n",
    "        os.makedirs(landmark_dir)    \n",
    "\n",
    "    main()\n",
    "    \n",
    "    print(time.time()-begin)\n",
    "    \n",
    "#R_net 2320.5425374507904\n",
    "#O_net 3131.904032945633"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen_O48_TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    \n",
    "    for index,term in enumerate(terms):\n",
    "        num=0\n",
    "        print(\"%s start\"%(term))\n",
    "        with tf.python_io.TFRecordWriter(\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\%s_train.tfrecords\"%(img_size,term)) as writer:\n",
    "            with open(r'E:\\friedhelm\\object\\face_detection_MTCNN\\DATA\\%d\\%s.txt'%(img_size,term)) as readlines:\n",
    "                readlines=[line.strip().split(' ') for line in readlines]\n",
    "                random.shuffle(readlines)\n",
    "                for i,line in enumerate(readlines):\n",
    "                    if(i%50000==0):\n",
    "                        print(i)\n",
    "                    img=cv2.imread(line[0].replace('/','\\\\'))\n",
    "                    img_raw = img.tobytes()\n",
    "                    label=int(line[1])\n",
    "                    roi=[0.0]*4               \n",
    "                    landmark=[0.0]*10\n",
    "                    if(len(line)==6):    \n",
    "                        roi=[float(_) for _ in line[2:6]]   \n",
    "                    if(len(line)==12):\n",
    "                        landmark=[float(_) for _ in line[2:12]]                  \n",
    "                    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                        'img': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "                        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label])),\n",
    "                        \"roi\": tf.train.Feature(float_list=tf.train.FloatList(value=roi)),\n",
    "                        \"landmark\": tf.train.Feature(float_list=tf.train.FloatList(value=landmark)),\n",
    "                    }))\n",
    "                    writer.write(example.SerializeToString())  #序列化为字符串  \n",
    "                    num+=1\n",
    "                    if(num==base*scale[index]):\n",
    "                        print(\"%s finish\"%(term))\n",
    "                        break\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    img_size=48\n",
    "    #change img_size to P R O net\n",
    "    terms=['neg_%d'%(img_size),'pos_%d'%(img_size),'par_%d'%(img_size),'land_%d'%(img_size)]\n",
    "    scale=[3,1,1,2]\n",
    "    base=180000\n",
    "\n",
    "    begin=time.time()\n",
    "\n",
    "    main()\n",
    "    \n",
    "    print(time.time()-begin)\n",
    "\n",
    "#Pnet train_data               \n",
    "#neg 645017\n",
    "#par 507206\n",
    "#pos 285560 \n",
    "#land 584332\n",
    "    \n",
    "#Rnet train_data neg_pics 758503 in total,pos_pics 285017 in total,par_pics 572771 in total land \n",
    "\n",
    "#29951.208035707474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_O48model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from core.tool import read_multi_tfrecords,image_color_distort\n",
    "from core.MTCNN_model import Pnet_model,Rnet_model,Onet_model\n",
    "from train.train_tool import label_los,roi_los,landmark_los,cal_accuracy\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def train(image,label,roi,landmark,model,model_name):\n",
    "    \n",
    "    _label, _roi ,_landmark=model(image,batch)\n",
    "    \n",
    "    with tf.name_scope('output'):\n",
    "        _label=tf.squeeze(_label,name='label')\n",
    "        _roi=tf.squeeze(_roi,name='roi')\n",
    "        _landmark=tf.squeeze(_landmark,name='landmark')\n",
    "        \n",
    "    _label_los=label_los(_label,label)\n",
    "    _box_los=roi_los(label,_roi,roi)    \n",
    "    _landmark_los=landmark_los(label,_landmark,landmark)\n",
    "    \n",
    "    function_loss=_label_los*ratio[0]+_box_los*ratio[1]+_landmark_los*ratio[2]\n",
    "\n",
    "    tf.add_to_collection(\"loss\", function_loss)\n",
    "    loss_all=tf.get_collection('loss')\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        loss=tf.reduce_sum(loss_all)\n",
    "        tf.summary.scalar('loss',loss) \n",
    "        \n",
    "    opt=tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        train_accuracy=cal_accuracy(_label,label)\n",
    "        tf.summary.scalar('accuracy',train_accuracy) \n",
    "\n",
    "    saver=tf.train.Saver()\n",
    "    merged=tf.summary.merge_all() \n",
    "    \n",
    "    images,labels,rois,landmarks=read_multi_tfrecords(addr,batch_size,img_size)   \n",
    "    images=image_color_distort(images)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run((tf.global_variables_initializer(),\n",
    "                  tf.local_variables_initializer()))\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        image_batch,label_batch,roi_batch,landmark_batch=sess.run([images,labels,rois,landmarks])\n",
    "        \n",
    "        writer_train=tf.summary.FileWriter('C:\\\\Users\\\\312\\\\Desktop\\\\',sess.graph)\n",
    "        try:\n",
    "            \n",
    "            for i in range(1,train_step):\n",
    "                \n",
    "                image_batch,label_batch,roi_batch,landmark_batch=sess.run([images,labels,rois,landmarks])\n",
    "                \n",
    "                sess.run(opt,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch})\n",
    "                if(i%100==0):\n",
    "                    summary=sess.run(merged,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch})\n",
    "                    writer_train.add_summary(summary,i) \n",
    "                if(i%1000==0):\n",
    "                    print('次数',i)    \n",
    "                    print('train_accuracy',sess.run(train_accuracy,feed_dict={image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch}))\n",
    "                    print('loss',sess.run(loss,{image:image_batch,label:label_batch,roi:roi_batch,landmark:landmark_batch}))               \n",
    "                    print('time',time.time()-begin)\n",
    "                    if(i%10000==0):\n",
    "                        saver.save(sess,\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\%s\\\\%s_%d.ckpt\"%(model_name,model_name,i))\n",
    "        except  tf.errors.OutOfRangeError:\n",
    "            print(\"finished\")\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            writer_train.close()\n",
    "        coord.join(threads)\n",
    "    \n",
    "def main(model):\n",
    "    \n",
    "    with tf.name_scope('input'):\n",
    "        image=tf.placeholder(tf.float32,name='image')\n",
    "        label=tf.placeholder(tf.int32,name='label')\n",
    "        roi=tf.placeholder(tf.float32,name='roi')\n",
    "        landmark = tf.placeholder(tf.float32,name='landmark')  \n",
    "\n",
    "    train(image,label,roi,landmark,model,model_name)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    img_size=48\n",
    "    batch=448\n",
    "    batch_size=[192,64,64,128]\n",
    "    addr=[\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\neg_%d_train.tfrecords\"%(img_size,img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\pos_%d_train.tfrecords\"%(img_size,img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\par_%d_train.tfrecords\"%(img_size,img_size),\n",
    "          \"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\DATA\\\\%d\\\\land_%d_train.tfrecords\"%(img_size,img_size)]  \n",
    "\n",
    "    model=Onet_model\n",
    "    model_name=\"Onet_model\"    \n",
    "    train_step=100001\n",
    "    learning_rate=0.001\n",
    "    \n",
    "    save_model_path=\"E:\\\\friedhelm\\\\object\\\\face_detection_MTCNN\\\\%s\"%(model_name)\n",
    "    if not os.path.exists(save_model_path):\n",
    "        os.makedirs(save_model_path) \n",
    "        \n",
    "    if(model_name==\"Onet_model\"):\n",
    "        ratio=[1,0.5,1]\n",
    "    else:\n",
    "        ratio=[1,0.5,0.5]\n",
    "    \n",
    "\n",
    "    begin=time.time()        \n",
    "    main(model)\n",
    "# tensorboard --logdir=C:\\\\Users\\\\312\\\\Desktop\\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=[[1,2,3,4,5,6],[7,8,9,7,8,9]]\n",
    "# np.vstack(a)\n",
    "np.concatenate(a,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1])\n",
    "b=np.array([2])\n",
    "c=[]\n",
    "c.append(a)\n",
    "c.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.vstack([[1,2,3,4],[2,4,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=b[:,2]-b[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,1]*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(b[:,1]-b[:,0]>1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(b,np.where(b[:,1]-b[:,0]>1)[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.zeros((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]=(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[[]]=(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(t_box,w,h):\n",
    "    \"\"\"\n",
    "    used for pad t_box that out of range\n",
    "\n",
    "    input : t_box; wide,high of img\n",
    "    output: boundingbox after pad\n",
    "\n",
    "    format of input  : \n",
    "        t_box : [x1,y1,x2,y2] \n",
    "        w       : int\n",
    "        h       : int\n",
    "\n",
    "    format of output : \n",
    "        t_box    : [x1,y1,x2,y2]\n",
    "    \"\"\"  \n",
    "    xl_idx=np.where((t_box[:,0]<0))[0]  \n",
    "    t_box[xl_idx]=0\n",
    "\n",
    "    yl_idx=np.where((t_box[:,1]<0))[0]  \n",
    "    t_box[yl_idx]=0  \n",
    "\n",
    "    xr_idx=np.where((t_box[:,2]>w))[0]  \n",
    "    t_box[xr_idx]=w-1\n",
    "\n",
    "    yr_idx=np.where((t_box[:,3]>h))[0]  \n",
    "    t_box[yr_idx]=h-1  \n",
    "\n",
    "    return t_box\n",
    "\n",
    "\n",
    "\n",
    "def calibrate_box(img,NMS_box,model_name=\"default\"):\n",
    "    \"\"\"\n",
    "    used for calibrating NMS_box\n",
    "\n",
    "    input : boundingbox after nms, img\n",
    "    output: score , boundingbox after calibrate , landmark_box\n",
    "\n",
    "    format of input  : \n",
    "        NMS_box : -1*[x1,y1,x2,y2,score,offset_x1,offset_y1,offset_x2,offset_y2,5*(landmark_x,landmark_y)] \n",
    "        img          : np.array()\n",
    "\n",
    "    format of output : \n",
    "        score_box    : list of score -1*[score]\n",
    "        net_box      : list of box   -1*[face_x1,face_x2,face_y1,face_y2]\n",
    "        landmark_box : list of box   -1*[5*(true_landmark_x,true_landmark_y)]\n",
    "    \"\"\"\n",
    "    h,w,c=img.shape\n",
    "\n",
    "    t_box=np.zeros((NMS_box.shape[0],4))\n",
    "    boxes=np.vstack(NMS_box)\n",
    "\n",
    "    bounding_box=boxes[:,0:4]\n",
    "    score_box=boxes[:,4]\n",
    "    delta_box=boxes[:,5:9]\n",
    "\n",
    "    t_w=bounding_box[:,2]-bounding_box[:,0]+1\n",
    "    t_h=bounding_box[:,3]-bounding_box[:,1]+1\n",
    "\n",
    "    w_h=np.vstack([t_w,t_h,t_w,t_h])\n",
    "    t_box=bounding_box+delta_box*w_h\n",
    "\n",
    "    delete_idx=np.where((t_box[:,2]-t_box[:,0]<self.min_face_size)|(t_box[:,3]-t_box[:,1]<self.min_face_size))[0]\n",
    "    t_box=np.delete(t_box,delete_idx,0)\n",
    "\n",
    "\n",
    "    net_box=pad(t_box,w,h)\n",
    "\n",
    "    if(model_name==\"Onet\"):\n",
    "        boxes=np.delete(boxes,delete_idx,0)\n",
    "        score_box=boxes[:,4]\n",
    "        landmark_box=np.zeros((len(boxes),5,2))\n",
    "        for i in range(5):\n",
    "            landmark_box[:,i,:]=(boxes[:,9+i*2]*(t_box[:,2]-t_box[:,0])+t_box[:,0],boxes[:,9+i*2+1]*(t_box[:,3]-t_box[:,1])+t_box[:,1])   \n",
    "    else: \n",
    "        score_box=np.delete(score_box,delete_idx,0)\n",
    "\n",
    "    return score_box,net_box,landmark_box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
